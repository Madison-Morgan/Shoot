{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Classification for Rock Paper Scissors Moves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: Madison Morgan, 2020\n",
    "\n",
    "Here is a notebook that demos two different types of deep learning image classifiers.\n",
    "For Rock Paper Scissors Moves to be used in an app. Here is demonstrated and tested:\n",
    "    A developed CNN model and a MobileVNET model.\n",
    "    \n",
    "Credits: I referenced a few notebooks, tutorials, and data \n",
    "* https://colab.research.google.com/github/trekhleb/machine-learning-experiments/blob/master/experiments/rock_paper_scissors_mobilenet_v2/rock_paper_scissors_mobilenet_v2.ipynb#scrollTo=DJ8jGFnTLt8t\n",
    "* https://www.tensorflow.org/tutorials/images/data_augmentation\n",
    "\n",
    "Data:\n",
    "* http://laurencemoroney.com/rock-paper-scissors-dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 1.0 [Importing Packages and Defining Constants](#1.0)\n",
    "* 2.0 [Data Preprocessing](#2.0)\n",
    "    * 2.1 [Data Preprocessing: CNN Model](#2.1)\n",
    "    * 2.2 [Defining Data Generators](#2.2)\n",
    "* 3.0 [Defining the Models](#3.0)\n",
    "    * 3.1[Defining the Models: CNN Model](#3.1)\n",
    "    * 3.2[Defining the Models: MobileNetV2](#3.2)\n",
    "* 4.0 [Training the Models](#4.0)\n",
    "    * 4.1[Training the Models: CNN Model](#4.1)\n",
    "    * 4.2[Training the Models: MobileNetV2](#4.2)\n",
    "* 5.0 [Evaluating Accuracy and Loss of Model](#5.0)\n",
    "    * 5.1 [Comparing MobileNetV2 Training](#5.1)\n",
    "* 6.0 [Testing the Model](#6.0)\n",
    "* 7.0 [Saving Model as TF.Lite for App](#7.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Packages and Defining Constants <a class=\"anchor\" id=\"1.0\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential,Model\n",
    "from tensorflow.keras.layers import Input,Conv2D, MaxPooling2D, Flatten, Dropout, Dense\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define some constants\n",
    "DATA_PATH =\"C://Users//haide//Desktop//MadyProjectz//RPS//Shoot//downloaded//\"\n",
    "TRAIN_PATH = \"C://Users//haide//Desktop//MadyProjectz//RPS//Shoot//data//train//\"\n",
    "TEST_PATH = \"C://Users//haide//Desktop//MadyProjectz//RPS//Shoot//data//test//\"\n",
    "VALIDATION_PATH = \"C://Users//haide//Desktop//MadyProjectz//RPS//Shoot//data//validation//\"\n",
    "BEST_MODEL_PATH_CNN = \"best_model_cnn.h5\"\n",
    "BEST_MODEL_PATH_MBNET = \"best_model_mbnet.h5\"\n",
    "INPUT_SHAPE = (128,128,3)\n",
    "TARGET_SIZE = (128,128)\n",
    "BATCH_SIZE = 32\n",
    "CLASS_MODE = 'categorical'\n",
    "TF_DATASET = 'rock_paper_scissors'\n",
    "TRAINING_SIZE = 0.9 #train CNN with 90% of images\n",
    "TESTING_SIZE = 0.05 #test CNN with 5% of images\n",
    "VALIDATION_SIZE = 0.05 #validate CNN with 5% of images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing <a class=\"anchor\" id=\"2.0\"></a>\n",
    "Importing the data and seeing what the heck it looks like"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing: CNN Model <a class=\"anchor\" id=\"2.1\"></a>\n",
    "Need only run once, hence commented out to avoid accidentally rerunning, essentially sorted the nescessary files into the proper directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(len(os.listdir(DATA_PATH+\"/paper\")))\n",
    "#print(len(os.listdir(DATA_PATH+\"/rock\")))\n",
    "#print(len(os.listdir(DATA_PATH+\"/scissors\")))\n",
    "\n",
    "#def moveFiles(files,src,dest):\n",
    " #   for file in files:\n",
    "  #      full_file_name = os.path.join(src, file)\n",
    "   #     if os.path.isfile(full_file_name):\n",
    "    #        shutil.copy(full_file_name,dest)\n",
    "\n",
    "\n",
    "#def separateData():\n",
    " #   for move in ['paper','rock','scissors']:\n",
    "  #      files = os.listdir(DATA_PATH+move)\n",
    "   #     train_index = math.ceil(len(files)*0.9)\n",
    "    #    test_index = train_index+ math.ceil(len(files)*0.05)\n",
    "     #   validation_index = test_index+ math.floor(len(files)*0.05)\n",
    "    \n",
    "      #  moveFiles(files[:train_index],DATA_PATH+move,TRAIN_PATH+move)\n",
    "       # moveFiles(files[train_index:test_index],DATA_PATH+move,TEST_PATH+move)\n",
    "        #moveFiles(files[test_index:validation_index],DATA_PATH+move,VALIDATION_PATH+move)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Data Generators <a class=\"anchor\" id=\"2.2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4490 images belonging to 3 classes.\n",
      "Found 483 images belonging to 3 classes.\n",
      "Found 107 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "data_generator = ImageDataGenerator(rescale=1. / 255, rotation_range=90, width_shift_range=0.2,\n",
    "                            height_shift_range=0.2, horizontal_flip=True, vertical_flip=True, brightness_range=[0.2,1.0], shear_range=0.2, zoom_range=[0.5,1.0], fill_mode='nearest')\n",
    "\n",
    "validation_generator = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = data_generator.flow_from_directory(\n",
    "    TRAIN_PATH,\n",
    "    target_size=TARGET_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=CLASS_MODE,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "\n",
    "test_generator = data_generator.flow_from_directory(\n",
    "    TEST_PATH,\n",
    "    target_size=TARGET_SIZE,\n",
    "    batch_size=1,\n",
    "    class_mode=CLASS_MODE\n",
    ")\n",
    "\n",
    "validation_generator = validation_generator.flow_from_directory(\n",
    "    VALIDATION_PATH,\n",
    "    target_size=TARGET_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=CLASS_MODE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Important to note the labels are diff order\n",
    "#label_cnn = {[1,0,0]: 'paper', [0,1,0]:'rock', [0,0,1]:'scissors'}\n",
    "x,y = train_generator.next()\n",
    "plt.imshow(x[0])\n",
    "plt.title(\"Label: \"+str(y[0]))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the Model <a class=\"anchor\" id=\"3.0\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the Model: CNN Model <a class=\"anchor\" id=\"3.1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(tf.keras.Model):\n",
    "    def __init__(self, dataPath, inputShape):\n",
    "        super(CNN,self).__init__()\n",
    "        self.datapath = dataPath\n",
    "        self.model = self.build_model(inputShape)\n",
    "        self.model.compile(loss='categorical_crossentropy',\n",
    "             optimizer='rmsprop',\n",
    "             metrics=['accuracy'])\n",
    "        self.model.summary()\n",
    "        \n",
    "    \n",
    "    def build_model(self, inputShape):\n",
    "        input_model = Input(shape=(inputShape))\n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(64, (3, 3), input_shape=inputShape, activation='relu'))\n",
    "        #model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "        model.add(MaxPooling2D((2, 2)))\n",
    "        model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "        model.add(MaxPooling2D((2, 2)))\n",
    "        #model.add(Dropout(0.2))\n",
    "\n",
    "        model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "        #model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "        model.add(MaxPooling2D((2, 2)))\n",
    "        model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "        model.add(MaxPooling2D((2, 2)))\n",
    "        #model.add(Dropout(0.2))\n",
    "\n",
    "        model.add(Flatten())\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(512, activation='relu'))\n",
    "        model.add(Dense(3, activation='softmax'))\n",
    "        \n",
    "        model.summary()\n",
    "        output_model=model(input_model)\n",
    "        model = Model(input_model,output_model)\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_16 (Conv2D)           (None, 126, 126, 64)      1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 63, 63, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 61, 61, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 28, 28, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 12, 12, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 512)               2359808   \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 3)                 1539      \n",
      "=================================================================\n",
      "Total params: 2,621,507\n",
      "Trainable params: 2,621,507\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_8 (InputLayer)         [(None, 128, 128, 3)]     0         \n",
      "_________________________________________________________________\n",
      "sequential_4 (Sequential)    (None, 3)                 2621507   \n",
      "=================================================================\n",
      "Total params: 2,621,507\n",
      "Trainable params: 2,621,507\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "CNN = CNN(DATA_PATH, INPUT_SHAPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback = ModelCheckpoint(\n",
    "    BEST_MODEL_PATH_CNN, \n",
    "    monitor='val_accuracy',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "reduce_callback  = ReduceLROnPlateau(\n",
    "    monitor = 'val_accuracy',\n",
    "    patience = 3,\n",
    "    factor = 0.5,\n",
    "    min_lr = 0.00001,\n",
    "    verbose = 1\n",
    ")\n",
    "\n",
    "callbacks_list = [checkpoint_callback, reduce_callback]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the Model: MobileNetV2 for Feature Extraction <a class=\"anchor\" id=\"3.2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"mobilenetv2_1.00_128\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_9 (InputLayer)            [(None, 128, 128, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Conv1 (Conv2D)                  (None, 64, 64, 32)   864         input_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bn_Conv1 (BatchNormalization)   (None, 64, 64, 32)   128         Conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "Conv1_relu (ReLU)               (None, 64, 64, 32)   0           bn_Conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_depthwise (Depthw (None, 64, 64, 32)   288         Conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_depthwise_BN (Bat (None, 64, 64, 32)   128         expanded_conv_depthwise[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_depthwise_relu (R (None, 64, 64, 32)   0           expanded_conv_depthwise_BN[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_project (Conv2D)  (None, 64, 64, 16)   512         expanded_conv_depthwise_relu[0][0\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_project_BN (Batch (None, 64, 64, 16)   64          expanded_conv_project[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_1_expand (Conv2D)         (None, 64, 64, 96)   1536        expanded_conv_project_BN[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block_1_expand_BN (BatchNormali (None, 64, 64, 96)   384         block_1_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_1_expand_relu (ReLU)      (None, 64, 64, 96)   0           block_1_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_1_pad (ZeroPadding2D)     (None, 65, 65, 96)   0           block_1_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_1_depthwise (DepthwiseCon (None, 32, 32, 96)   864         block_1_pad[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_1_depthwise_BN (BatchNorm (None, 32, 32, 96)   384         block_1_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_1_depthwise_relu (ReLU)   (None, 32, 32, 96)   0           block_1_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_1_project (Conv2D)        (None, 32, 32, 24)   2304        block_1_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_1_project_BN (BatchNormal (None, 32, 32, 24)   96          block_1_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2_expand (Conv2D)         (None, 32, 32, 144)  3456        block_1_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_2_expand_BN (BatchNormali (None, 32, 32, 144)  576         block_2_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_2_expand_relu (ReLU)      (None, 32, 32, 144)  0           block_2_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_2_depthwise (DepthwiseCon (None, 32, 32, 144)  1296        block_2_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_2_depthwise_BN (BatchNorm (None, 32, 32, 144)  576         block_2_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_2_depthwise_relu (ReLU)   (None, 32, 32, 144)  0           block_2_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_2_project (Conv2D)        (None, 32, 32, 24)   3456        block_2_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_2_project_BN (BatchNormal (None, 32, 32, 24)   96          block_2_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2_add (Add)               (None, 32, 32, 24)   0           block_1_project_BN[0][0]         \n",
      "                                                                 block_2_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_3_expand (Conv2D)         (None, 32, 32, 144)  3456        block_2_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_3_expand_BN (BatchNormali (None, 32, 32, 144)  576         block_3_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_3_expand_relu (ReLU)      (None, 32, 32, 144)  0           block_3_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_3_pad (ZeroPadding2D)     (None, 33, 33, 144)  0           block_3_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_3_depthwise (DepthwiseCon (None, 16, 16, 144)  1296        block_3_pad[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_3_depthwise_BN (BatchNorm (None, 16, 16, 144)  576         block_3_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_3_depthwise_relu (ReLU)   (None, 16, 16, 144)  0           block_3_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_3_project (Conv2D)        (None, 16, 16, 32)   4608        block_3_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_3_project_BN (BatchNormal (None, 16, 16, 32)   128         block_3_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4_expand (Conv2D)         (None, 16, 16, 192)  6144        block_3_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_4_expand_BN (BatchNormali (None, 16, 16, 192)  768         block_4_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_4_expand_relu (ReLU)      (None, 16, 16, 192)  0           block_4_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_4_depthwise (DepthwiseCon (None, 16, 16, 192)  1728        block_4_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_4_depthwise_BN (BatchNorm (None, 16, 16, 192)  768         block_4_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_4_depthwise_relu (ReLU)   (None, 16, 16, 192)  0           block_4_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_4_project (Conv2D)        (None, 16, 16, 32)   6144        block_4_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_4_project_BN (BatchNormal (None, 16, 16, 32)   128         block_4_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4_add (Add)               (None, 16, 16, 32)   0           block_3_project_BN[0][0]         \n",
      "                                                                 block_4_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_5_expand (Conv2D)         (None, 16, 16, 192)  6144        block_4_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_5_expand_BN (BatchNormali (None, 16, 16, 192)  768         block_5_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_5_expand_relu (ReLU)      (None, 16, 16, 192)  0           block_5_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_5_depthwise (DepthwiseCon (None, 16, 16, 192)  1728        block_5_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_5_depthwise_BN (BatchNorm (None, 16, 16, 192)  768         block_5_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_5_depthwise_relu (ReLU)   (None, 16, 16, 192)  0           block_5_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_5_project (Conv2D)        (None, 16, 16, 32)   6144        block_5_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_5_project_BN (BatchNormal (None, 16, 16, 32)   128         block_5_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_5_add (Add)               (None, 16, 16, 32)   0           block_4_add[0][0]                \n",
      "                                                                 block_5_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_6_expand (Conv2D)         (None, 16, 16, 192)  6144        block_5_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_6_expand_BN (BatchNormali (None, 16, 16, 192)  768         block_6_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_6_expand_relu (ReLU)      (None, 16, 16, 192)  0           block_6_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_6_pad (ZeroPadding2D)     (None, 17, 17, 192)  0           block_6_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_6_depthwise (DepthwiseCon (None, 8, 8, 192)    1728        block_6_pad[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_6_depthwise_BN (BatchNorm (None, 8, 8, 192)    768         block_6_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_6_depthwise_relu (ReLU)   (None, 8, 8, 192)    0           block_6_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_6_project (Conv2D)        (None, 8, 8, 64)     12288       block_6_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_6_project_BN (BatchNormal (None, 8, 8, 64)     256         block_6_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_7_expand (Conv2D)         (None, 8, 8, 384)    24576       block_6_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_7_expand_BN (BatchNormali (None, 8, 8, 384)    1536        block_7_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_7_expand_relu (ReLU)      (None, 8, 8, 384)    0           block_7_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_7_depthwise (DepthwiseCon (None, 8, 8, 384)    3456        block_7_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_7_depthwise_BN (BatchNorm (None, 8, 8, 384)    1536        block_7_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_7_depthwise_relu (ReLU)   (None, 8, 8, 384)    0           block_7_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_7_project (Conv2D)        (None, 8, 8, 64)     24576       block_7_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_7_project_BN (BatchNormal (None, 8, 8, 64)     256         block_7_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_7_add (Add)               (None, 8, 8, 64)     0           block_6_project_BN[0][0]         \n",
      "                                                                 block_7_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_8_expand (Conv2D)         (None, 8, 8, 384)    24576       block_7_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_8_expand_BN (BatchNormali (None, 8, 8, 384)    1536        block_8_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_8_expand_relu (ReLU)      (None, 8, 8, 384)    0           block_8_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_8_depthwise (DepthwiseCon (None, 8, 8, 384)    3456        block_8_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_8_depthwise_BN (BatchNorm (None, 8, 8, 384)    1536        block_8_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_8_depthwise_relu (ReLU)   (None, 8, 8, 384)    0           block_8_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_8_project (Conv2D)        (None, 8, 8, 64)     24576       block_8_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_8_project_BN (BatchNormal (None, 8, 8, 64)     256         block_8_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_8_add (Add)               (None, 8, 8, 64)     0           block_7_add[0][0]                \n",
      "                                                                 block_8_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_9_expand (Conv2D)         (None, 8, 8, 384)    24576       block_8_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_9_expand_BN (BatchNormali (None, 8, 8, 384)    1536        block_9_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_9_expand_relu (ReLU)      (None, 8, 8, 384)    0           block_9_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_9_depthwise (DepthwiseCon (None, 8, 8, 384)    3456        block_9_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_9_depthwise_BN (BatchNorm (None, 8, 8, 384)    1536        block_9_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_9_depthwise_relu (ReLU)   (None, 8, 8, 384)    0           block_9_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_9_project (Conv2D)        (None, 8, 8, 64)     24576       block_9_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_9_project_BN (BatchNormal (None, 8, 8, 64)     256         block_9_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_9_add (Add)               (None, 8, 8, 64)     0           block_8_add[0][0]                \n",
      "                                                                 block_9_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_10_expand (Conv2D)        (None, 8, 8, 384)    24576       block_9_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_10_expand_BN (BatchNormal (None, 8, 8, 384)    1536        block_10_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_10_expand_relu (ReLU)     (None, 8, 8, 384)    0           block_10_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_10_depthwise (DepthwiseCo (None, 8, 8, 384)    3456        block_10_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_10_depthwise_BN (BatchNor (None, 8, 8, 384)    1536        block_10_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_10_depthwise_relu (ReLU)  (None, 8, 8, 384)    0           block_10_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_10_project (Conv2D)       (None, 8, 8, 96)     36864       block_10_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_10_project_BN (BatchNorma (None, 8, 8, 96)     384         block_10_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_11_expand (Conv2D)        (None, 8, 8, 576)    55296       block_10_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_11_expand_BN (BatchNormal (None, 8, 8, 576)    2304        block_11_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_11_expand_relu (ReLU)     (None, 8, 8, 576)    0           block_11_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_11_depthwise (DepthwiseCo (None, 8, 8, 576)    5184        block_11_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_11_depthwise_BN (BatchNor (None, 8, 8, 576)    2304        block_11_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_11_depthwise_relu (ReLU)  (None, 8, 8, 576)    0           block_11_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_11_project (Conv2D)       (None, 8, 8, 96)     55296       block_11_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_11_project_BN (BatchNorma (None, 8, 8, 96)     384         block_11_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_11_add (Add)              (None, 8, 8, 96)     0           block_10_project_BN[0][0]        \n",
      "                                                                 block_11_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_12_expand (Conv2D)        (None, 8, 8, 576)    55296       block_11_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_12_expand_BN (BatchNormal (None, 8, 8, 576)    2304        block_12_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_12_expand_relu (ReLU)     (None, 8, 8, 576)    0           block_12_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_12_depthwise (DepthwiseCo (None, 8, 8, 576)    5184        block_12_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_12_depthwise_BN (BatchNor (None, 8, 8, 576)    2304        block_12_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_12_depthwise_relu (ReLU)  (None, 8, 8, 576)    0           block_12_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_12_project (Conv2D)       (None, 8, 8, 96)     55296       block_12_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_12_project_BN (BatchNorma (None, 8, 8, 96)     384         block_12_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_12_add (Add)              (None, 8, 8, 96)     0           block_11_add[0][0]               \n",
      "                                                                 block_12_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_13_expand (Conv2D)        (None, 8, 8, 576)    55296       block_12_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_13_expand_BN (BatchNormal (None, 8, 8, 576)    2304        block_13_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_13_expand_relu (ReLU)     (None, 8, 8, 576)    0           block_13_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_13_pad (ZeroPadding2D)    (None, 9, 9, 576)    0           block_13_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_13_depthwise (DepthwiseCo (None, 4, 4, 576)    5184        block_13_pad[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_13_depthwise_BN (BatchNor (None, 4, 4, 576)    2304        block_13_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_13_depthwise_relu (ReLU)  (None, 4, 4, 576)    0           block_13_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_13_project (Conv2D)       (None, 4, 4, 160)    92160       block_13_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_13_project_BN (BatchNorma (None, 4, 4, 160)    640         block_13_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_14_expand (Conv2D)        (None, 4, 4, 960)    153600      block_13_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_14_expand_BN (BatchNormal (None, 4, 4, 960)    3840        block_14_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_14_expand_relu (ReLU)     (None, 4, 4, 960)    0           block_14_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_14_depthwise (DepthwiseCo (None, 4, 4, 960)    8640        block_14_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_14_depthwise_BN (BatchNor (None, 4, 4, 960)    3840        block_14_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_14_depthwise_relu (ReLU)  (None, 4, 4, 960)    0           block_14_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_14_project (Conv2D)       (None, 4, 4, 160)    153600      block_14_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_14_project_BN (BatchNorma (None, 4, 4, 160)    640         block_14_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_14_add (Add)              (None, 4, 4, 160)    0           block_13_project_BN[0][0]        \n",
      "                                                                 block_14_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_15_expand (Conv2D)        (None, 4, 4, 960)    153600      block_14_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_15_expand_BN (BatchNormal (None, 4, 4, 960)    3840        block_15_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_15_expand_relu (ReLU)     (None, 4, 4, 960)    0           block_15_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_15_depthwise (DepthwiseCo (None, 4, 4, 960)    8640        block_15_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_15_depthwise_BN (BatchNor (None, 4, 4, 960)    3840        block_15_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_15_depthwise_relu (ReLU)  (None, 4, 4, 960)    0           block_15_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_15_project (Conv2D)       (None, 4, 4, 160)    153600      block_15_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_15_project_BN (BatchNorma (None, 4, 4, 160)    640         block_15_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_15_add (Add)              (None, 4, 4, 160)    0           block_14_add[0][0]               \n",
      "                                                                 block_15_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_16_expand (Conv2D)        (None, 4, 4, 960)    153600      block_15_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_16_expand_BN (BatchNormal (None, 4, 4, 960)    3840        block_16_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_16_expand_relu (ReLU)     (None, 4, 4, 960)    0           block_16_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_16_depthwise (DepthwiseCo (None, 4, 4, 960)    8640        block_16_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_16_depthwise_BN (BatchNor (None, 4, 4, 960)    3840        block_16_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_16_depthwise_relu (ReLU)  (None, 4, 4, 960)    0           block_16_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_16_project (Conv2D)       (None, 4, 4, 320)    307200      block_16_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_16_project_BN (BatchNorma (None, 4, 4, 320)    1280        block_16_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "Conv_1 (Conv2D)                 (None, 4, 4, 1280)   409600      block_16_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Conv_1_bn (BatchNormalization)  (None, 4, 4, 1280)   5120        Conv_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "out_relu (ReLU)                 (None, 4, 4, 1280)   0           Conv_1_bn[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 1280)         0           out_relu[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 2,257,984\n",
      "Trainable params: 0\n",
      "Non-trainable params: 2,257,984\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model = tf.keras.applications.MobileNetV2(\n",
    "  input_shape=INPUT_SHAPE,\n",
    "  include_top=False,\n",
    "  weights='imagenet',\n",
    "  pooling='avg'\n",
    ")\n",
    "\n",
    "# Freezing base model, dont want to retrain only want feature extraction!\n",
    "base_model.trainable= False\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Failed to import pydot. You must `pip install pydot` and install graphviz (https://graphviz.gitlab.io/download/), ', 'for `pydotprint` to work.')\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(\n",
    "base_model,\n",
    "show_shapes=True,\n",
    "show_layer_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding a Classification Head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "mobilenetv2_1.00_128 (Functi (None, 1280)              2257984   \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 3)                 3843      \n",
      "=================================================================\n",
      "Total params: 2,261,827\n",
      "Trainable params: 3,843\n",
      "Non-trainable params: 2,257,984\n",
      "_________________________________________________________________\n",
      "('Failed to import pydot. You must `pip install pydot` and install graphviz (https://graphviz.gitlab.io/download/), ', 'for `pydotprint` to work.')\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "model.add(base_model)\n",
    "\n",
    "# model.add(tf.keras.layers.GlobalAveragePooling2D())\n",
    "\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "\n",
    "model.add(tf.keras.layers.Dense(\n",
    "    units=3, #NUM_CLASSES,\n",
    "    activation=tf.keras.activations.softmax,\n",
    "    kernel_regularizer=tf.keras.regularizers.l2(l=0.01)\n",
    "))\n",
    "\n",
    "model.summary()\n",
    "tf.keras.utils.plot_model(\n",
    "    model,\n",
    "    show_shapes=True,\n",
    "    show_layer_names=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compiling the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmsprop_optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.001)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=rmsprop_optimizer,\n",
    "    loss=tf.keras.losses.categorical_crossentropy,\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Model <a class=\"anchor\" id=\"4.0\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_size_train = train_generator.n//train_generator.batch_size\n",
    "step_size_val = validation_generator.n//validation_generator.batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model : CNN Model <a class=\"anchor\" id=\"4.1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "140/140 [==============================] - ETA: 0s - loss: 1.2296 - accuracy: 0.3595\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.58333, saving model to best_model_cnn.h5\n",
      "140/140 [==============================] - 152s 1s/step - loss: 1.2289 - accuracy: 0.3595 - val_loss: 1.0831 - val_accuracy: 0.5833\n",
      "Epoch 2/25\n",
      "140/140 [==============================] - ETA: 0s - loss: 1.0845 - accuracy: 0.3986\n",
      "Epoch 00002: val_accuracy improved from 0.58333 to 0.71875, saving model to best_model_cnn.h5\n",
      "140/140 [==============================] - 144s 1s/step - loss: 1.0844 - accuracy: 0.3988 - val_loss: 0.8920 - val_accuracy: 0.7188\n",
      "Epoch 3/25\n",
      "140/140 [==============================] - ETA: 0s - loss: 1.0313 - accuracy: 0.4838\n",
      "Epoch 00003: val_accuracy did not improve from 0.71875\n",
      "140/140 [==============================] - 145s 1s/step - loss: 1.0312 - accuracy: 0.4839 - val_loss: 0.8836 - val_accuracy: 0.7083\n",
      "Epoch 4/25\n",
      "140/140 [==============================] - ETA: 0s - loss: 0.9639 - accuracy: 0.5493\n",
      "Epoch 00004: val_accuracy did not improve from 0.71875\n",
      "140/140 [==============================] - 150s 1s/step - loss: 0.9636 - accuracy: 0.5496 - val_loss: 0.6569 - val_accuracy: 0.6771\n",
      "Epoch 5/25\n",
      "140/140 [==============================] - ETA: 0s - loss: 0.8325 - accuracy: 0.6305\n",
      "Epoch 00005: val_accuracy improved from 0.71875 to 0.78125, saving model to best_model_cnn.h5\n",
      "140/140 [==============================] - 141s 1s/step - loss: 0.8322 - accuracy: 0.6307 - val_loss: 0.5444 - val_accuracy: 0.7812\n",
      "Epoch 6/25\n",
      "140/140 [==============================] - ETA: 0s - loss: 0.7068 - accuracy: 0.7181\n",
      "Epoch 00006: val_accuracy improved from 0.78125 to 0.96875, saving model to best_model_cnn.h5\n",
      "140/140 [==============================] - 139s 994ms/step - loss: 0.7068 - accuracy: 0.7181 - val_loss: 0.1777 - val_accuracy: 0.9688\n",
      "Epoch 7/25\n",
      "140/140 [==============================] - ETA: 0s - loss: 0.6181 - accuracy: 0.7606\n",
      "Epoch 00007: val_accuracy did not improve from 0.96875\n",
      "140/140 [==============================] - 140s 997ms/step - loss: 0.6180 - accuracy: 0.7607 - val_loss: 0.2430 - val_accuracy: 0.8854\n",
      "Epoch 8/25\n",
      "140/140 [==============================] - ETA: 0s - loss: 0.5376 - accuracy: 0.7917\n",
      "Epoch 00008: val_accuracy did not improve from 0.96875\n",
      "140/140 [==============================] - 139s 990ms/step - loss: 0.5377 - accuracy: 0.7916 - val_loss: 0.2264 - val_accuracy: 0.9271\n",
      "Epoch 9/25\n",
      "140/140 [==============================] - ETA: 0s - loss: 0.4979 - accuracy: 0.8100\n",
      "Epoch 00009: val_accuracy did not improve from 0.96875\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "140/140 [==============================] - 135s 964ms/step - loss: 0.4980 - accuracy: 0.8100 - val_loss: 0.2142 - val_accuracy: 0.8958\n",
      "Epoch 10/25\n",
      "140/140 [==============================] - ETA: 0s - loss: 0.3933 - accuracy: 0.8571\n",
      "Epoch 00010: val_accuracy did not improve from 0.96875\n",
      "140/140 [==============================] - 135s 964ms/step - loss: 0.3933 - accuracy: 0.8571 - val_loss: 0.1313 - val_accuracy: 0.9479\n",
      "Epoch 11/25\n",
      "140/140 [==============================] - ETA: 0s - loss: 0.3715 - accuracy: 0.8680\n",
      "Epoch 00011: val_accuracy did not improve from 0.96875\n",
      "140/140 [==============================] - 137s 975ms/step - loss: 0.3715 - accuracy: 0.8680 - val_loss: 0.1076 - val_accuracy: 0.9583\n",
      "Epoch 12/25\n",
      "140/140 [==============================] - ETA: 0s - loss: 0.3315 - accuracy: 0.8863\n",
      "Epoch 00012: val_accuracy did not improve from 0.96875\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "140/140 [==============================] - 136s 967ms/step - loss: 0.3315 - accuracy: 0.8862 - val_loss: 0.0952 - val_accuracy: 0.9583\n",
      "Epoch 13/25\n",
      "140/140 [==============================] - ETA: 0s - loss: 0.2993 - accuracy: 0.8988\n",
      "Epoch 00013: val_accuracy did not improve from 0.96875\n",
      "140/140 [==============================] - 136s 973ms/step - loss: 0.2992 - accuracy: 0.8988 - val_loss: 0.0688 - val_accuracy: 0.9688\n",
      "Epoch 14/25\n",
      "140/140 [==============================] - ETA: 0s - loss: 0.2529 - accuracy: 0.9138\n",
      "Epoch 00014: val_accuracy did not improve from 0.96875\n",
      "140/140 [==============================] - 136s 971ms/step - loss: 0.2530 - accuracy: 0.9137 - val_loss: 0.0987 - val_accuracy: 0.9583\n",
      "Epoch 15/25\n",
      "140/140 [==============================] - ETA: 0s - loss: 0.2812 - accuracy: 0.9061\n",
      "Epoch 00015: val_accuracy did not improve from 0.96875\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "140/140 [==============================] - 139s 989ms/step - loss: 0.2811 - accuracy: 0.9062 - val_loss: 0.0887 - val_accuracy: 0.9688\n",
      "Epoch 16/25\n",
      "140/140 [==============================] - ETA: 0s - loss: 0.2477 - accuracy: 0.9143\n",
      "Epoch 00016: val_accuracy improved from 0.96875 to 0.97917, saving model to best_model_cnn.h5\n",
      "140/140 [==============================] - 137s 979ms/step - loss: 0.2477 - accuracy: 0.9144 - val_loss: 0.0673 - val_accuracy: 0.9792\n",
      "Epoch 17/25\n",
      "140/140 [==============================] - ETA: 0s - loss: 0.2241 - accuracy: 0.9256\n",
      "Epoch 00017: val_accuracy did not improve from 0.97917\n",
      "140/140 [==============================] - 136s 973ms/step - loss: 0.2241 - accuracy: 0.9256 - val_loss: 0.0694 - val_accuracy: 0.9792\n",
      "Epoch 18/25\n",
      "140/140 [==============================] - ETA: 0s - loss: 0.2186 - accuracy: 0.9225\n",
      "Epoch 00018: val_accuracy did not improve from 0.97917\n",
      "140/140 [==============================] - 138s 985ms/step - loss: 0.2187 - accuracy: 0.9225 - val_loss: 0.1110 - val_accuracy: 0.9688\n",
      "Epoch 19/25\n",
      "140/140 [==============================] - ETA: 0s - loss: 0.2183 - accuracy: 0.9221\n",
      "Epoch 00019: val_accuracy did not improve from 0.97917\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "140/140 [==============================] - 139s 992ms/step - loss: 0.2183 - accuracy: 0.9221 - val_loss: 0.0715 - val_accuracy: 0.9792\n",
      "Epoch 20/25\n",
      "140/140 [==============================] - ETA: 0s - loss: 0.2124 - accuracy: 0.9323\n",
      "Epoch 00020: val_accuracy did not improve from 0.97917\n",
      "140/140 [==============================] - 139s 995ms/step - loss: 0.2124 - accuracy: 0.9322 - val_loss: 0.1026 - val_accuracy: 0.9688\n",
      "Epoch 21/25\n",
      "140/140 [==============================] - ETA: 0s - loss: 0.1998 - accuracy: 0.9303\n",
      "Epoch 00021: val_accuracy did not improve from 0.97917\n",
      "140/140 [==============================] - 141s 1s/step - loss: 0.1998 - accuracy: 0.9303 - val_loss: 0.0823 - val_accuracy: 0.9583\n",
      "Epoch 22/25\n",
      "140/140 [==============================] - ETA: 0s - loss: 0.2070 - accuracy: 0.9312\n",
      "Epoch 00022: val_accuracy did not improve from 0.97917\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "140/140 [==============================] - 140s 998ms/step - loss: 0.2070 - accuracy: 0.9312 - val_loss: 0.0997 - val_accuracy: 0.9583\n",
      "Epoch 23/25\n",
      "140/140 [==============================] - ETA: 0s - loss: 0.2015 - accuracy: 0.9289\n",
      "Epoch 00023: val_accuracy did not improve from 0.97917\n",
      "140/140 [==============================] - 139s 995ms/step - loss: 0.2015 - accuracy: 0.9290 - val_loss: 0.1075 - val_accuracy: 0.9583\n",
      "Epoch 24/25\n",
      "140/140 [==============================] - ETA: 0s - loss: 0.2223 - accuracy: 0.9256\n",
      "Epoch 00024: val_accuracy did not improve from 0.97917\n",
      "140/140 [==============================] - 140s 998ms/step - loss: 0.2222 - accuracy: 0.9256 - val_loss: 0.1496 - val_accuracy: 0.9583\n",
      "Epoch 25/25\n",
      "140/140 [==============================] - ETA: 0s - loss: 0.1924 - accuracy: 0.9349\n",
      "Epoch 00025: val_accuracy did not improve from 0.97917\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "140/140 [==============================] - 140s 996ms/step - loss: 0.1925 - accuracy: 0.9348 - val_loss: 0.1313 - val_accuracy: 0.9583\n"
     ]
    }
   ],
   "source": [
    "CNN.history = CNN.model.fit(x=train_generator,\n",
    "                   steps_per_epoch=step_size_train,\n",
    "                   epochs=25,\n",
    "                   validation_data=validation_generator,\n",
    "                   validation_steps=step_size_val,\n",
    "                   verbose=1,\n",
    "                   shuffle=True,\n",
    "                   callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model : MobileNetV2 <a class=\"anchor\" id=\"4.2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "140/140 [==============================] - ETA: 0s - loss: 1.0727 - accuracy: 0.5827\n",
      "Epoch 00001: val_accuracy did not improve from 0.97917\n",
      "140/140 [==============================] - 63s 435ms/step - loss: 1.0708 - accuracy: 0.5834 - val_loss: 0.2520 - val_accuracy: 0.9688\n",
      "Epoch 2/25\n",
      "140/140 [==============================] - ETA: 0s - loss: 0.5547 - accuracy: 0.8005\n",
      "Epoch 00002: val_accuracy did not improve from 0.97917\n",
      "140/140 [==============================] - 64s 459ms/step - loss: 0.5544 - accuracy: 0.8007 - val_loss: 0.2239 - val_accuracy: 0.9479\n",
      "Epoch 3/25\n",
      "140/140 [==============================] - ETA: 0s - loss: 0.4688 - accuracy: 0.8325\n",
      "Epoch 00003: val_accuracy did not improve from 0.97917\n",
      "140/140 [==============================] - 61s 434ms/step - loss: 0.4685 - accuracy: 0.8327 - val_loss: 0.1825 - val_accuracy: 0.9688\n",
      "Epoch 4/25\n",
      "140/140 [==============================] - ETA: 0s - loss: 0.4336 - accuracy: 0.8537\n",
      "Epoch 00004: val_accuracy did not improve from 0.97917\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "140/140 [==============================] - 60s 425ms/step - loss: 0.4335 - accuracy: 0.8537 - val_loss: 0.1690 - val_accuracy: 0.9583\n",
      "Epoch 5/25\n",
      "140/140 [==============================] - ETA: 0s - loss: 0.4115 - accuracy: 0.8664\n",
      "Epoch 00005: val_accuracy did not improve from 0.97917\n",
      "140/140 [==============================] - 60s 425ms/step - loss: 0.4114 - accuracy: 0.8665 - val_loss: 0.1586 - val_accuracy: 0.9688\n",
      "Epoch 6/25\n",
      "140/140 [==============================] - ETA: 0s - loss: 0.3872 - accuracy: 0.8644\n",
      "Epoch 00006: val_accuracy did not improve from 0.97917\n",
      "140/140 [==============================] - 59s 421ms/step - loss: 0.3872 - accuracy: 0.8644 - val_loss: 0.1644 - val_accuracy: 0.9583\n",
      "Epoch 7/25\n",
      "140/140 [==============================] - ETA: 0s - loss: 0.3780 - accuracy: 0.8688\n",
      "Epoch 00007: val_accuracy did not improve from 0.97917\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "140/140 [==============================] - 60s 428ms/step - loss: 0.3780 - accuracy: 0.8688 - val_loss: 0.1652 - val_accuracy: 0.9583\n",
      "Epoch 8/25\n",
      "140/140 [==============================] - ETA: 0s - loss: 0.3775 - accuracy: 0.8707\n",
      "Epoch 00008: val_accuracy did not improve from 0.97917\n",
      "140/140 [==============================] - 62s 445ms/step - loss: 0.3775 - accuracy: 0.8707 - val_loss: 0.1717 - val_accuracy: 0.9583\n",
      "Epoch 9/25\n",
      "140/140 [==============================] - ETA: 0s - loss: 0.3599 - accuracy: 0.8785\n",
      "Epoch 00009: val_accuracy did not improve from 0.97917\n",
      "140/140 [==============================] - 58s 409ms/step - loss: 0.3599 - accuracy: 0.8785 - val_loss: 0.1657 - val_accuracy: 0.9583\n",
      "Epoch 10/25\n",
      "140/140 [==============================] - ETA: 0s - loss: 0.3496 - accuracy: 0.8910\n",
      "Epoch 00010: val_accuracy did not improve from 0.97917\n",
      "140/140 [==============================] - 57s 407ms/step - loss: 0.3495 - accuracy: 0.8910 - val_loss: 0.1555 - val_accuracy: 0.9792\n",
      "Epoch 11/25\n",
      "140/140 [==============================] - ETA: 0s - loss: 0.3799 - accuracy: 0.8754\n",
      "Epoch 00011: val_accuracy did not improve from 0.97917\n",
      "140/140 [==============================] - 61s 432ms/step - loss: 0.3799 - accuracy: 0.8755 - val_loss: 0.1771 - val_accuracy: 0.9583\n",
      "Epoch 12/25\n",
      "140/140 [==============================] - ETA: 0s - loss: 0.3488 - accuracy: 0.8901\n",
      "Epoch 00012: val_accuracy did not improve from 0.97917\n",
      "140/140 [==============================] - 63s 446ms/step - loss: 0.3489 - accuracy: 0.8901 - val_loss: 0.1882 - val_accuracy: 0.9583\n",
      "Epoch 13/25\n",
      "140/140 [==============================] - ETA: 0s - loss: 0.3661 - accuracy: 0.8777\n",
      "Epoch 00013: val_accuracy did not improve from 0.97917\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "140/140 [==============================] - 64s 457ms/step - loss: 0.3661 - accuracy: 0.8777 - val_loss: 0.1596 - val_accuracy: 0.9688\n",
      "Epoch 14/25\n",
      "140/140 [==============================] - ETA: 0s - loss: 0.3601 - accuracy: 0.8883\n",
      "Epoch 00014: val_accuracy did not improve from 0.97917\n",
      "140/140 [==============================] - 62s 439ms/step - loss: 0.3602 - accuracy: 0.8882 - val_loss: 0.1536 - val_accuracy: 0.9583\n",
      "Epoch 15/25\n",
      "140/140 [==============================] - ETA: 0s - loss: 0.3454 - accuracy: 0.8906\n",
      "Epoch 00015: val_accuracy did not improve from 0.97917\n",
      "140/140 [==============================] - 57s 408ms/step - loss: 0.3455 - accuracy: 0.8905 - val_loss: 0.1268 - val_accuracy: 0.9792\n",
      "Epoch 16/25\n",
      "140/140 [==============================] - ETA: 0s - loss: 0.3414 - accuracy: 0.8833\n",
      "Epoch 00016: val_accuracy did not improve from 0.97917\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "140/140 [==============================] - 57s 408ms/step - loss: 0.3414 - accuracy: 0.8833 - val_loss: 0.1650 - val_accuracy: 0.9583\n",
      "Epoch 17/25\n",
      "140/140 [==============================] - ETA: 0s - loss: 0.3315 - accuracy: 0.8965\n",
      "Epoch 00017: val_accuracy did not improve from 0.97917\n",
      "140/140 [==============================] - 60s 430ms/step - loss: 0.3316 - accuracy: 0.8964 - val_loss: 0.1579 - val_accuracy: 0.9583\n",
      "Epoch 18/25\n",
      "140/140 [==============================] - ETA: 0s - loss: 0.3549 - accuracy: 0.8888\n",
      "Epoch 00018: val_accuracy did not improve from 0.97917\n",
      "140/140 [==============================] - 61s 436ms/step - loss: 0.3549 - accuracy: 0.8888 - val_loss: 0.1644 - val_accuracy: 0.9583\n",
      "Epoch 19/25\n",
      "140/140 [==============================] - ETA: 0s - loss: 0.3506 - accuracy: 0.8868\n",
      "Epoch 00019: val_accuracy did not improve from 0.97917\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "140/140 [==============================] - 62s 441ms/step - loss: 0.3506 - accuracy: 0.8868 - val_loss: 0.1341 - val_accuracy: 0.9792\n",
      "Epoch 20/25\n",
      "140/140 [==============================] - ETA: 0s - loss: 0.3691 - accuracy: 0.8770\n",
      "Epoch 00020: val_accuracy did not improve from 0.97917\n",
      "140/140 [==============================] - 62s 441ms/step - loss: 0.3692 - accuracy: 0.8770 - val_loss: 0.1552 - val_accuracy: 0.9688\n",
      "Epoch 21/25\n",
      "140/140 [==============================] - ETA: 0s - loss: 0.3668 - accuracy: 0.8752\n",
      "Epoch 00021: val_accuracy did not improve from 0.97917\n",
      "140/140 [==============================] - 61s 433ms/step - loss: 0.3668 - accuracy: 0.8752 - val_loss: 0.1581 - val_accuracy: 0.9688\n",
      "Epoch 22/25\n",
      "140/140 [==============================] - ETA: 0s - loss: 0.3613 - accuracy: 0.8812\n",
      "Epoch 00022: val_accuracy did not improve from 0.97917\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "140/140 [==============================] - 59s 421ms/step - loss: 0.3613 - accuracy: 0.8813 - val_loss: 0.1676 - val_accuracy: 0.9583\n",
      "Epoch 23/25\n",
      "140/140 [==============================] - ETA: 0s - loss: 0.3579 - accuracy: 0.8832\n",
      "Epoch 00023: val_accuracy did not improve from 0.97917\n",
      "140/140 [==============================] - 83s 595ms/step - loss: 0.3579 - accuracy: 0.8832 - val_loss: 0.1718 - val_accuracy: 0.9583\n",
      "Epoch 24/25\n",
      "140/140 [==============================] - ETA: 0s - loss: 0.3504 - accuracy: 0.8850\n",
      "Epoch 00024: val_accuracy did not improve from 0.97917\n",
      "140/140 [==============================] - 59s 423ms/step - loss: 0.3504 - accuracy: 0.8850 - val_loss: 0.1644 - val_accuracy: 0.9583\n",
      "Epoch 25/25\n",
      "140/140 [==============================] - ETA: 0s - loss: 0.3503 - accuracy: 0.8852\n",
      "Epoch 00025: val_accuracy did not improve from 0.97917\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "140/140 [==============================] - 64s 454ms/step - loss: 0.3503 - accuracy: 0.8852 - val_loss: 0.1705 - val_accuracy: 0.9583\n"
     ]
    }
   ],
   "source": [
    "training_history = model.fit(x= train_generator,\n",
    "    steps_per_epoch = step_size_train,\n",
    "    epochs=25, \n",
    "    validation_data=validation_generator,\n",
    "    validation_steps = step_size_val,\n",
    "    verbose =1,\n",
    "    shuffle=True,\n",
    "    callbacks=callbacks_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-Tuning the Training\n",
    "Here we try to unfreeze some of the top layers of \n",
    "the base_model to train it a little bit more so to adjust top layers to our Rock-Paper-Scissors dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of layers in the base model:  155\n"
     ]
    }
   ],
   "source": [
    "# Un-freeze the top layers of the model\n",
    "base_model.trainable = True\n",
    "\n",
    "print(\"Number of layers in the base model: \", len(base_model.layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "mobilenetv2_1.00_128 (Functi (None, 1280)              2257984   \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 3)                 3843      \n",
      "=================================================================\n",
      "Total params: 2,261,827\n",
      "Trainable params: 723,843\n",
      "Non-trainable params: 1,537,984\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Fine tune from this layer onwards.\n",
    "fine_tune_at = 149\n",
    "\n",
    "# Freeze all the layers before the `fine_tune_at` layer\n",
    "for layer in base_model.layers[:fine_tune_at]:\n",
    "    layer.trainable =  False\n",
    "    \n",
    "# Compile the model using a much-lower training rate.\n",
    "adam_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "rmsprop_optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.0001)\n",
    "model.compile(\n",
    "    optimizer = rmsprop_optimizer,\n",
    "    loss=tf.keras.losses.categorical_crossentropy,\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n",
    "\n",
    "# The number of additional epochs during which we're going to fine tune the model.\n",
    "fine_tuning_epochs = 10\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/35\n",
      "140/140 [==============================] - ETA: 0s - loss: 0.3506 - accuracy: 0.8820\n",
      "Epoch 00001: val_accuracy did not improve from 0.97917\n",
      "140/140 [==============================] - 89s 583ms/step - loss: 0.3506 - accuracy: 0.8820 - val_loss: 0.1510 - val_accuracy: 0.9583\n",
      "Epoch 2/35\n",
      "140/140 [==============================] - ETA: 0s - loss: 0.2957 - accuracy: 0.9014\n",
      "Epoch 00002: val_accuracy did not improve from 0.97917\n",
      "140/140 [==============================] - 77s 547ms/step - loss: 0.2955 - accuracy: 0.9015 - val_loss: 0.2524 - val_accuracy: 0.9271\n",
      "Epoch 3/35\n",
      "140/140 [==============================] - ETA: 0s - loss: 0.2565 - accuracy: 0.9241\n",
      "Epoch 00003: val_accuracy did not improve from 0.97917\n",
      "140/140 [==============================] - 64s 458ms/step - loss: 0.2565 - accuracy: 0.9241 - val_loss: 0.2545 - val_accuracy: 0.9375\n",
      "Epoch 4/35\n",
      "140/140 [==============================] - ETA: 0s - loss: 0.2400 - accuracy: 0.9264\n",
      "Epoch 00004: val_accuracy did not improve from 0.97917\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "140/140 [==============================] - 79s 564ms/step - loss: 0.2399 - accuracy: 0.9264 - val_loss: 0.4750 - val_accuracy: 0.8750\n",
      "Epoch 5/35\n",
      "140/140 [==============================] - ETA: 0s - loss: 0.2222 - accuracy: 0.9360\n",
      "Epoch 00005: val_accuracy did not improve from 0.97917\n",
      "140/140 [==============================] - 75s 536ms/step - loss: 0.2222 - accuracy: 0.9360 - val_loss: 0.4587 - val_accuracy: 0.8958\n",
      "Epoch 6/35\n",
      "140/140 [==============================] - ETA: 0s - loss: 0.2180 - accuracy: 0.9400\n",
      "Epoch 00006: val_accuracy did not improve from 0.97917\n",
      "140/140 [==============================] - 72s 512ms/step - loss: 0.2180 - accuracy: 0.9400 - val_loss: 0.2373 - val_accuracy: 0.9271\n",
      "Epoch 7/35\n",
      "140/140 [==============================] - ETA: 0s - loss: 0.2056 - accuracy: 0.9435\n",
      "Epoch 00007: val_accuracy did not improve from 0.97917\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "140/140 [==============================] - 65s 462ms/step - loss: 0.2056 - accuracy: 0.9435 - val_loss: 0.2469 - val_accuracy: 0.9375\n",
      "Epoch 8/35\n",
      "140/140 [==============================] - ETA: 0s - loss: 0.1908 - accuracy: 0.9448\n",
      "Epoch 00008: val_accuracy did not improve from 0.97917\n",
      "140/140 [==============================] - 81s 575ms/step - loss: 0.1907 - accuracy: 0.9448 - val_loss: 0.1697 - val_accuracy: 0.9479\n",
      "Epoch 9/35\n",
      "140/140 [==============================] - ETA: 0s - loss: 0.1967 - accuracy: 0.9405\n",
      "Epoch 00009: val_accuracy did not improve from 0.97917\n",
      "140/140 [==============================] - 71s 502ms/step - loss: 0.1966 - accuracy: 0.9406 - val_loss: 0.1391 - val_accuracy: 0.9583\n",
      "Epoch 10/35\n",
      "140/140 [==============================] - ETA: 0s - loss: 0.1846 - accuracy: 0.9501\n",
      "Epoch 00010: val_accuracy did not improve from 0.97917\n",
      "140/140 [==============================] - 62s 439ms/step - loss: 0.1847 - accuracy: 0.9500 - val_loss: 0.1091 - val_accuracy: 0.9688\n",
      "Epoch 11/35\n",
      "140/140 [==============================] - ETA: 0s - loss: 0.1810 - accuracy: 0.9538\n",
      "Epoch 00011: val_accuracy did not improve from 0.97917\n",
      "140/140 [==============================] - 62s 444ms/step - loss: 0.1811 - accuracy: 0.9538 - val_loss: 0.1128 - val_accuracy: 0.9688\n",
      "Epoch 12/35\n",
      "140/140 [==============================] - ETA: 0s - loss: 0.1723 - accuracy: 0.9534\n",
      "Epoch 00012: val_accuracy did not improve from 0.97917\n",
      "140/140 [==============================] - 62s 440ms/step - loss: 0.1724 - accuracy: 0.9534 - val_loss: 0.1198 - val_accuracy: 0.9688\n",
      "Epoch 13/35\n",
      "140/140 [==============================] - ETA: 0s - loss: 0.1933 - accuracy: 0.9468\n",
      "Epoch 00013: val_accuracy did not improve from 0.97917\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "140/140 [==============================] - 66s 472ms/step - loss: 0.1933 - accuracy: 0.9468 - val_loss: 0.1170 - val_accuracy: 0.9688\n",
      "Epoch 14/35\n",
      "140/140 [==============================] - ETA: 0s - loss: 0.1749 - accuracy: 0.9514\n",
      "Epoch 00014: val_accuracy did not improve from 0.97917\n",
      "140/140 [==============================] - 70s 502ms/step - loss: 0.1749 - accuracy: 0.9514 - val_loss: 0.1323 - val_accuracy: 0.9688\n",
      "Epoch 15/35\n",
      "140/140 [==============================] - ETA: 0s - loss: 0.1587 - accuracy: 0.9599\n",
      "Epoch 00015: val_accuracy did not improve from 0.97917\n",
      "140/140 [==============================] - 77s 547ms/step - loss: 0.1588 - accuracy: 0.9598 - val_loss: 0.1120 - val_accuracy: 0.9688\n",
      "Epoch 16/35\n",
      "140/140 [==============================] - ETA: 0s - loss: 0.1703 - accuracy: 0.9563\n",
      "Epoch 00016: val_accuracy did not improve from 0.97917\n",
      "140/140 [==============================] - 73s 517ms/step - loss: 0.1703 - accuracy: 0.9563 - val_loss: 0.0817 - val_accuracy: 0.9792\n",
      "Epoch 17/35\n",
      "140/140 [==============================] - ETA: 0s - loss: 0.1705 - accuracy: 0.9507\n",
      "Epoch 00017: val_accuracy did not improve from 0.97917\n",
      "140/140 [==============================] - 72s 509ms/step - loss: 0.1706 - accuracy: 0.9507 - val_loss: 0.1013 - val_accuracy: 0.9688\n",
      "Epoch 18/35\n",
      "140/140 [==============================] - ETA: 0s - loss: 0.1874 - accuracy: 0.9518\n",
      "Epoch 00018: val_accuracy did not improve from 0.97917\n",
      "140/140 [==============================] - 70s 496ms/step - loss: 0.1875 - accuracy: 0.9517 - val_loss: 0.1058 - val_accuracy: 0.9688\n",
      "Epoch 19/35\n",
      "140/140 [==============================] - ETA: 0s - loss: 0.1716 - accuracy: 0.9558\n",
      "Epoch 00019: val_accuracy did not improve from 0.97917\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "140/140 [==============================] - 72s 513ms/step - loss: 0.1717 - accuracy: 0.9558 - val_loss: 0.1054 - val_accuracy: 0.9688\n",
      "Epoch 20/35\n",
      "140/140 [==============================] - ETA: 0s - loss: 0.1861 - accuracy: 0.9532\n",
      "Epoch 00020: val_accuracy did not improve from 0.97917\n",
      "140/140 [==============================] - 67s 478ms/step - loss: 0.1861 - accuracy: 0.9532 - val_loss: 0.1001 - val_accuracy: 0.9688\n",
      "Epoch 21/35\n",
      "140/140 [==============================] - ETA: 0s - loss: 0.1851 - accuracy: 0.9516\n",
      "Epoch 00021: val_accuracy did not improve from 0.97917\n",
      "140/140 [==============================] - 61s 438ms/step - loss: 0.1851 - accuracy: 0.9516 - val_loss: 0.0902 - val_accuracy: 0.9792\n",
      "Epoch 22/35\n",
      "140/140 [==============================] - ETA: 0s - loss: 0.1707 - accuracy: 0.9549\n",
      "Epoch 00022: val_accuracy did not improve from 0.97917\n",
      "140/140 [==============================] - 61s 436ms/step - loss: 0.1706 - accuracy: 0.9549 - val_loss: 0.1155 - val_accuracy: 0.9688\n",
      "Epoch 23/35\n",
      "140/140 [==============================] - ETA: 0s - loss: 0.1796 - accuracy: 0.9512\n",
      "Epoch 00023: val_accuracy did not improve from 0.97917\n",
      "140/140 [==============================] - 63s 447ms/step - loss: 0.1795 - accuracy: 0.9512 - val_loss: 0.0944 - val_accuracy: 0.9792\n",
      "Epoch 24/35\n",
      "140/140 [==============================] - ETA: 0s - loss: 0.1890 - accuracy: 0.9439\n",
      "Epoch 00024: val_accuracy did not improve from 0.97917\n",
      "140/140 [==============================] - 62s 440ms/step - loss: 0.1889 - accuracy: 0.9440 - val_loss: 0.1028 - val_accuracy: 0.9688\n",
      "Epoch 25/35\n",
      "140/140 [==============================] - ETA: 0s - loss: 0.1780 - accuracy: 0.9523\n",
      "Epoch 00025: val_accuracy did not improve from 0.97917\n",
      "140/140 [==============================] - 62s 438ms/step - loss: 0.1778 - accuracy: 0.9523 - val_loss: 0.0995 - val_accuracy: 0.9688\n",
      "Epoch 26/35\n",
      "140/140 [==============================] - ETA: 0s - loss: 0.1778 - accuracy: 0.9536\n",
      "Epoch 00026: val_accuracy did not improve from 0.97917\n",
      "140/140 [==============================] - 62s 439ms/step - loss: 0.1777 - accuracy: 0.9536 - val_loss: 0.1009 - val_accuracy: 0.9688\n",
      "Epoch 27/35\n",
      "140/140 [==============================] - ETA: 0s - loss: 0.1777 - accuracy: 0.9525\n",
      "Epoch 00027: val_accuracy did not improve from 0.97917\n",
      "140/140 [==============================] - 61s 438ms/step - loss: 0.1776 - accuracy: 0.9526 - val_loss: 0.1108 - val_accuracy: 0.9688\n",
      "Epoch 28/35\n",
      "140/140 [==============================] - ETA: 0s - loss: 0.1741 - accuracy: 0.9492\n",
      "Epoch 00028: val_accuracy did not improve from 0.97917\n",
      "140/140 [==============================] - 61s 438ms/step - loss: 0.1740 - accuracy: 0.9492 - val_loss: 0.1004 - val_accuracy: 0.9688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/35\n",
      "140/140 [==============================] - ETA: 0s - loss: 0.1589 - accuracy: 0.9561\n",
      "Epoch 00029: val_accuracy did not improve from 0.97917\n",
      "140/140 [==============================] - 61s 436ms/step - loss: 0.1590 - accuracy: 0.9561 - val_loss: 0.1000 - val_accuracy: 0.9688\n",
      "Epoch 30/35\n",
      "140/140 [==============================] - ETA: 0s - loss: 0.1752 - accuracy: 0.9496\n",
      "Epoch 00030: val_accuracy did not improve from 0.97917\n",
      "140/140 [==============================] - 61s 435ms/step - loss: 0.1752 - accuracy: 0.9497 - val_loss: 0.0947 - val_accuracy: 0.9792\n",
      "Epoch 31/35\n",
      "140/140 [==============================] - ETA: 0s - loss: 0.1592 - accuracy: 0.9552\n",
      "Epoch 00031: val_accuracy did not improve from 0.97917\n",
      "140/140 [==============================] - 61s 437ms/step - loss: 0.1592 - accuracy: 0.9553 - val_loss: 0.1037 - val_accuracy: 0.9688\n",
      "Epoch 32/35\n",
      "140/140 [==============================] - ETA: 0s - loss: 0.1608 - accuracy: 0.9561\n",
      "Epoch 00032: val_accuracy did not improve from 0.97917\n",
      "140/140 [==============================] - 61s 434ms/step - loss: 0.1608 - accuracy: 0.9561 - val_loss: 0.0841 - val_accuracy: 0.9792\n",
      "Epoch 33/35\n",
      "140/140 [==============================] - ETA: 0s - loss: 0.1459 - accuracy: 0.9600\n",
      "Epoch 00033: val_accuracy did not improve from 0.97917\n",
      "140/140 [==============================] - 61s 437ms/step - loss: 0.1460 - accuracy: 0.9600 - val_loss: 0.1053 - val_accuracy: 0.9688\n",
      "Epoch 34/35\n",
      "140/140 [==============================] - ETA: 0s - loss: 0.1551 - accuracy: 0.9561\n",
      "Epoch 00034: val_accuracy did not improve from 0.97917\n",
      "140/140 [==============================] - 62s 439ms/step - loss: 0.1551 - accuracy: 0.9561 - val_loss: 0.1095 - val_accuracy: 0.9688\n",
      "Epoch 35/35\n",
      "140/140 [==============================] - ETA: 0s - loss: 0.1609 - accuracy: 0.9576\n",
      "Epoch 00035: val_accuracy did not improve from 0.97917\n",
      "140/140 [==============================] - 62s 438ms/step - loss: 0.1610 - accuracy: 0.9576 - val_loss: 0.1138 - val_accuracy: 0.9688\n"
     ]
    }
   ],
   "source": [
    "training_history_fine = model.fit(\n",
    "    x= train_generator,\n",
    "    steps_per_epoch = step_size_train,\n",
    "    epochs=25+fine_tuning_epochs, \n",
    "    validation_data=validation_generator,\n",
    "    validation_steps = step_size_val,\n",
    "    verbose =1,\n",
    "    shuffle=True,\n",
    "    callbacks=callbacks_list)\n",
    "    \n",
    "    #initial_epoch=initial_epochs,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Accuracy and Loss of Model <a class=\"anchor\" id=\"5.0\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_loss_accuracy(history):\n",
    "    #show the keys contained in history\n",
    "    #print(history.keys())\n",
    "    \n",
    "    #get the accuracy and loss values for training and validation data\n",
    "    accuracy = history['accuracy']\n",
    "    validation_accuracy = history['val_accuracy']\n",
    "    loss = history['loss']\n",
    "    validation_loss = history['val_loss']\n",
    "    \n",
    "    num_epochs = range(len(accuracy))\n",
    "    plt.plot(num_epochs, accuracy, 'r', label='Training Accuracy')\n",
    "    plt.plot(num_epochs, validation_accuracy, 'b', label='Validation Accuracy')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.legend(loc=0)\n",
    "    plt.figure()\n",
    "    plt.show()\n",
    "    \n",
    "    plt.plot(num_epochs, loss, 'r', label='Training Loss')\n",
    "    plt.plot(num_epochs, validation_loss, 'b', label='Validation Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.legend(loc=0)\n",
    "    plt.figure()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the training & validation, loss and accuracy of the CNN model\n",
    "evaluate_loss_accuracy(CNN.history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'History' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-49-db18f90500ee>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#check the training & validation, loss and accuracy of the CNN model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mevaluate_loss_accuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_history\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-48-222f36dc5a0b>\u001b[0m in \u001b[0;36mevaluate_loss_accuracy\u001b[1;34m(history)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;31m#get the accuracy and loss values for training and validation data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mvalidation_accuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'History' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "#check the training & validation, loss and accuracy of the CNN model\n",
    "evaluate_loss_accuracy(training_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing MobileNetV2 Training<a class=\"anchor\" id=\"5.1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = training_history.history['loss'] + training_history_fine.history['loss']\n",
    "val_loss = training_history.history['val_loss'] + training_history_fine.history['val_loss']\n",
    "\n",
    "accuracy = training_history.history['accuracy'] + training_history_fine.history['accuracy']\n",
    "val_accuracy = training_history.history['val_accuracy'] + training_history_fine.history['val_accuracy']\n",
    "\n",
    "plt.figure(figsize=(14, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.plot(loss, label='Training set')\n",
    "plt.plot(val_loss, label='Test set', linestyle='--')\n",
    "plt.plot(\n",
    "[initial_epochs, initial_epochs], \n",
    "plt.ylim(),\n",
    "label='Start Fine Tuning',\n",
    "linestyle='--'\n",
    ")\n",
    "plt.legend()\n",
    "plt.grid(linestyle='--', linewidth=1, alpha=0.5)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.plot(accuracy, label='Training set')\n",
    "plt.plot(val_accuracy, label='Test set', linestyle='--')\n",
    "plt.plot(\n",
    "[initial_epochs, initial_epochs], \n",
    "plt.ylim(),\n",
    "label='Start Fine Tuning',\n",
    "linestyle='--'\n",
    ")\n",
    "plt.legend()\n",
    "plt.grid(linestyle='--', linewidth=1, alpha=0.5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture\n",
    "train_loss, train_accuracy = model.evaluate(\n",
    "    x=dataset_train.batch(BATCH_SIZE).take(NUM_TRAIN_EXAMPLES)\n",
    ")\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(\n",
    "    x=dataset_test.batch(BATCH_SIZE).take(NUM_TEST_EXAMPLES)\n",
    ")\n",
    "\n",
    "print('Training loss: ', train_loss)\n",
    "print('Training accuracy: ', train_accuracy)\n",
    "print('\\n')\n",
    "print('Test loss: ', test_loss)\n",
    "print('Test accuracy: ', test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the Model <a class=\"anchor\" id=\"6.0\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN.model.load_weights(BEST_MODEL_PATH_CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "483/483 [==============================] - 7s 15ms/step - loss: 0.5332 - accuracy: 0.8240\n"
     ]
    }
   ],
   "source": [
    "testing_model = CNN.model.evaluate(\n",
    "    test_generator,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = CNN.model.predict(test_generator, test_generator.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.9459732e-01 9.9311670e-05 5.3032562e-03]\n",
      " [8.5038356e-02 5.2565938e-01 3.8930231e-01]\n",
      " [4.8132735e-01 3.6978346e-01 1.4888917e-01]\n",
      " ...\n",
      " [2.6699146e-02 9.4913149e-01 2.4169452e-02]\n",
      " [2.1073852e-01 2.3584032e-01 5.5342114e-01]\n",
      " [9.9928087e-01 6.3140341e-08 7.1904517e-04]]\n"
     ]
    }
   ],
   "source": [
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "483"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_generator.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_generator.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Functional' object has no attribute 'predict_classes'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-bc310fe34fc5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m     \u001b[0mimg_class\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCNN\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_classes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"File: \"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\", pred: \"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_class\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Functional' object has no attribute 'predict_classes'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.preprocessing import image\n",
    "from PIL import Image\n",
    "import cv2\n",
    "path = \"C://Users//haide//Desktop//MadyProjectz//RPS//Shoot//data///testNEWPHOTOS//\"\n",
    "for file in os.listdir(path):\n",
    "    img = Image.open(path+file)#, target_size(60,60))\n",
    "    #print(img.mode)\n",
    "    img.load()\n",
    "    background = Image.new(\"RGB\", img.size, (255,255,255))\n",
    "    background.paste(img,mask=img.split()[3])\n",
    "    img = background\n",
    "    img = img.resize((60,60)) \n",
    "    img = image.img_to_array(img)\n",
    "    #print(img.shape)\n",
    "    imgplot = plt.imshow(img)\n",
    "    img = img.reshape((1,)+img.shape)\n",
    "    #print(img.shape)\n",
    "    \n",
    "    \n",
    "    img_class = CNN.model.predict_classes(img)\n",
    "    print(\"File: \"+str(file)+\", pred: \"+str(img_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(img_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Model as TF.Lite for App <a class=\"anchor\" id=\"7.0\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\"best_model.h5\")\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model.tflite', 'wb') as f:\n",
    "  f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
