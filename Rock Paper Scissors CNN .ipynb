{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dropout, Dense\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import shutil\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define some constants\n",
    "DATA_PATH =\"C://Users//haide//Desktop//MadyProjectz//RPS//Shoot//downloaded//\"\n",
    "TRAIN_PATH = \"C://Users//haide//Desktop//MadyProjectz//RPS//Shoot//data//train//\"\n",
    "TEST_PATH = \"C://Users//haide//Desktop//MadyProjectz//RPS//Shoot//data//test//\"\n",
    "VALIDATION_PATH = \"C://Users//haide//Desktop//MadyProjectz//RPS//Shoot//data//validation//\"\n",
    "BEST_MODEL_PATH = \"best_model.h5\"\n",
    "INPUT_SHAPE = (60,60,3)\n",
    "BATCH_SIZE = 32\n",
    "CLASS_MODE = 'categorical'\n",
    "TRAINING_SIZE = 0.9 #train CNN with 90% of images\n",
    "TESTING_SIZE = 0.05 #test CNN with 5% of images\n",
    "VALIDATION_SIZE = 0.05 #validate CNN with 5% of images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712\n",
      "726\n",
      "750\n"
     ]
    }
   ],
   "source": [
    "print(len(os.listdir(DATA_PATH+\"/paper\")))\n",
    "print(len(os.listdir(DATA_PATH+\"/rock\")))\n",
    "print(len(os.listdir(DATA_PATH+\"/scissors\")))\n",
    "\n",
    "def moveFiles(files,src,dest):\n",
    "    for file in files:\n",
    "        full_file_name = os.path.join(src, file)\n",
    "        if os.path.isfile(full_file_name):\n",
    "            shutil.copy(full_file_name,dest)\n",
    "\n",
    "\n",
    "def separateData():\n",
    "    for move in ['paper','rock','scissors']:\n",
    "        files = os.listdir(DATA_PATH+move)\n",
    "        train_index = math.ceil(len(files)*0.9)\n",
    "        test_index = train_index+ math.ceil(len(files)*0.05)\n",
    "        validation_index = test_index+ math.floor(len(files)*0.05)\n",
    "    \n",
    "        moveFiles(files[:train_index],DATA_PATH+move,TRAIN_PATH+move)\n",
    "        moveFiles(files[train_index:test_index],DATA_PATH+move,TEST_PATH+move)\n",
    "        moveFiles(files[test_index:validation_index],DATA_PATH+move,VALIDATION_PATH+move)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1970 images belonging to 3 classes.\n",
      "Found 111 images belonging to 3 classes.\n",
      "Found 107 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "data_generator = ImageDataGenerator(rescale=1. / 255,\n",
    "                            rotation_range=40,\n",
    "                            width_shift_range=0.2,\n",
    "                            height_shift_range=0.2,\n",
    "                            zoom_range=0.2,\n",
    "                            horizontal_flip=True,\n",
    "                            fill_mode='nearest')\n",
    "\n",
    "train_generator = data_generator.flow_from_directory(\n",
    "    TRAIN_PATH,\n",
    "    target_size=(60,60),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=CLASS_MODE\n",
    ")\n",
    "\n",
    "\n",
    "test_generator = data_generator.flow_from_directory(\n",
    "    TEST_PATH,\n",
    "    target_size=(60,60),\n",
    "    batch_size=1,\n",
    "    class_mode=CLASS_MODE\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "validation_generator = data_generator.flow_from_directory(\n",
    "    VALIDATION_PATH,\n",
    "    target_size=(60,60),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=CLASS_MODE\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN:\n",
    "    def __init__(self, dataPath, inputShape):\n",
    "        self.datapath = dataPath\n",
    "        self.model = self.build_model(inputShape)\n",
    "        self.model.compile(loss='categorical_crossentropy',\n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])\n",
    "        \n",
    "    \n",
    "    def build_model(self, inputShape):\n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(64, (3, 3), input_shape=inputShape, activation='relu'))\n",
    "        model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "        model.add(MaxPooling2D((2, 2)))\n",
    "        model.add(Dropout(0.2))\n",
    "\n",
    "        model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "        model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "        model.add(MaxPooling2D((2, 2)))\n",
    "        model.add(Dropout(0.2))\n",
    "\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(256, activation='relu'))\n",
    "        model.add(Dropout(0.3))\n",
    "        model.add(Dense(3, activation='softmax'))\n",
    "        \n",
    "        model.summary()\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_8 (Conv2D)            (None, 58, 58, 64)        1792      \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 56, 56, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 26, 26, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 24, 24, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 18432)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 256)               4718848   \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 3)                 771       \n",
      "=================================================================\n",
      "Total params: 4,979,779\n",
      "Trainable params: 4,979,779\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "CNN = CNN(DATA_PATH, INPUT_SHAPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback = ModelCheckpoint(\n",
    "    BEST_MODEL_PATH, \n",
    "    monitor='val_accuracy',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "reduce_callback  = ReduceLROnPlateau(\n",
    "    monitor = 'val_accuracy',\n",
    "    patience = 3,\n",
    "    factor = 0.5,\n",
    "    min_lr = 0.00001,\n",
    "    verbose = 1\n",
    ")\n",
    "\n",
    "callbacks_list = [checkpoint_callback, reduce_callback]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "60/61 [============================>.] - ETA: 0s - loss: 1.0840 - accuracy: 0.3851\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.41667, saving model to best_model.h5\n",
      "61/61 [==============================] - 9s 149ms/step - loss: 1.0841 - accuracy: 0.3854 - val_loss: 1.0794 - val_accuracy: 0.4167\n",
      "Epoch 2/30\n",
      "60/61 [============================>.] - ETA: 0s - loss: 1.0366 - accuracy: 0.4659\n",
      "Epoch 00002: val_accuracy improved from 0.41667 to 0.50000, saving model to best_model.h5\n",
      "61/61 [==============================] - 8s 138ms/step - loss: 1.0369 - accuracy: 0.4665 - val_loss: 1.0147 - val_accuracy: 0.5000\n",
      "Epoch 3/30\n",
      "60/61 [============================>.] - ETA: 0s - loss: 0.8107 - accuracy: 0.6369\n",
      "Epoch 00003: val_accuracy improved from 0.50000 to 0.67708, saving model to best_model.h5\n",
      "61/61 [==============================] - 9s 146ms/step - loss: 0.8090 - accuracy: 0.6388 - val_loss: 0.6528 - val_accuracy: 0.6771\n",
      "Epoch 4/30\n",
      "60/61 [============================>.] - ETA: 0s - loss: 0.5500 - accuracy: 0.7880\n",
      "Epoch 00004: val_accuracy improved from 0.67708 to 0.75000, saving model to best_model.h5\n",
      "61/61 [==============================] - 9s 144ms/step - loss: 0.5526 - accuracy: 0.7864 - val_loss: 0.5194 - val_accuracy: 0.7500\n",
      "Epoch 5/30\n",
      "60/61 [============================>.] - ETA: 0s - loss: 0.4901 - accuracy: 0.8048\n",
      "Epoch 00005: val_accuracy improved from 0.75000 to 0.83333, saving model to best_model.h5\n",
      "61/61 [==============================] - 9s 150ms/step - loss: 0.4899 - accuracy: 0.8039 - val_loss: 0.4391 - val_accuracy: 0.8333\n",
      "Epoch 6/30\n",
      "60/61 [============================>.] - ETA: 0s - loss: 0.3588 - accuracy: 0.8631\n",
      "Epoch 00006: val_accuracy improved from 0.83333 to 0.93750, saving model to best_model.h5\n",
      "61/61 [==============================] - 10s 163ms/step - loss: 0.3562 - accuracy: 0.8648 - val_loss: 0.2928 - val_accuracy: 0.9375\n",
      "Epoch 7/30\n",
      "60/61 [============================>.] - ETA: 0s - loss: 0.2446 - accuracy: 0.9150\n",
      "Epoch 00007: val_accuracy did not improve from 0.93750\n",
      "61/61 [==============================] - 9s 150ms/step - loss: 0.2427 - accuracy: 0.9154 - val_loss: 0.2337 - val_accuracy: 0.8958\n",
      "Epoch 8/30\n",
      "60/61 [============================>.] - ETA: 0s - loss: 0.2112 - accuracy: 0.9307\n",
      "Epoch 00008: val_accuracy improved from 0.93750 to 0.95833, saving model to best_model.h5\n",
      "61/61 [==============================] - 10s 159ms/step - loss: 0.2112 - accuracy: 0.9303 - val_loss: 0.1325 - val_accuracy: 0.9583\n",
      "Epoch 9/30\n",
      "60/61 [============================>.] - ETA: 0s - loss: 0.2019 - accuracy: 0.9292\n",
      "Epoch 00009: val_accuracy did not improve from 0.95833\n",
      "61/61 [==============================] - 9s 154ms/step - loss: 0.1989 - accuracy: 0.9303 - val_loss: 0.0894 - val_accuracy: 0.9583\n",
      "Epoch 10/30\n",
      "60/61 [============================>.] - ETA: 0s - loss: 0.1548 - accuracy: 0.9507\n",
      "Epoch 00010: val_accuracy improved from 0.95833 to 0.97917, saving model to best_model.h5\n",
      "61/61 [==============================] - 10s 157ms/step - loss: 0.1536 - accuracy: 0.9515 - val_loss: 0.0749 - val_accuracy: 0.9792\n",
      "Epoch 11/30\n",
      "60/61 [============================>.] - ETA: 0s - loss: 0.1469 - accuracy: 0.9481\n",
      "Epoch 00011: val_accuracy did not improve from 0.97917\n",
      "61/61 [==============================] - 11s 175ms/step - loss: 0.1459 - accuracy: 0.9484 - val_loss: 0.0772 - val_accuracy: 0.9583\n",
      "Epoch 12/30\n",
      "60/61 [============================>.] - ETA: 0s - loss: 0.1345 - accuracy: 0.9559\n",
      "Epoch 00012: val_accuracy did not improve from 0.97917\n",
      "61/61 [==============================] - 10s 171ms/step - loss: 0.1353 - accuracy: 0.9551 - val_loss: 0.1156 - val_accuracy: 0.9479\n",
      "Epoch 13/30\n",
      "60/61 [============================>.] - ETA: 0s - loss: 0.1260 - accuracy: 0.9573\n",
      "Epoch 00013: val_accuracy improved from 0.97917 to 0.98958, saving model to best_model.h5\n",
      "61/61 [==============================] - 11s 174ms/step - loss: 0.1249 - accuracy: 0.9580 - val_loss: 0.0625 - val_accuracy: 0.9896\n",
      "Epoch 14/30\n",
      "60/61 [============================>.] - ETA: 0s - loss: 0.1448 - accuracy: 0.9530\n",
      "Epoch 00014: val_accuracy did not improve from 0.98958\n",
      "61/61 [==============================] - 12s 193ms/step - loss: 0.1450 - accuracy: 0.9527 - val_loss: 0.0785 - val_accuracy: 0.9792\n",
      "Epoch 15/30\n",
      "60/61 [============================>.] - ETA: 0s - loss: 0.1188 - accuracy: 0.9627 ETA: 0s - loss: 0.1188 - accuracy: \n",
      "Epoch 00015: val_accuracy did not improve from 0.98958\n",
      "61/61 [==============================] - 11s 187ms/step - loss: 0.1187 - accuracy: 0.9628 - val_loss: 0.0401 - val_accuracy: 0.9896\n",
      "Epoch 16/30\n",
      "60/61 [============================>.] - ETA: 0s - loss: 0.0878 - accuracy: 0.9717\n",
      "Epoch 00016: val_accuracy did not improve from 0.98958\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "61/61 [==============================] - 11s 186ms/step - loss: 0.0891 - accuracy: 0.9706 - val_loss: 0.0511 - val_accuracy: 0.9896\n",
      "Epoch 17/30\n",
      "60/61 [============================>.] - ETA: 0s - loss: 0.0889 - accuracy: 0.9740\n",
      "Epoch 00017: val_accuracy did not improve from 0.98958\n",
      "61/61 [==============================] - 10s 165ms/step - loss: 0.0877 - accuracy: 0.9744 - val_loss: 0.0434 - val_accuracy: 0.9896\n",
      "Epoch 18/30\n",
      "60/61 [============================>.] - ETA: 0s - loss: 0.0620 - accuracy: 0.9795\n",
      "Epoch 00018: val_accuracy improved from 0.98958 to 1.00000, saving model to best_model.h5\n",
      "61/61 [==============================] - 11s 172ms/step - loss: 0.0611 - accuracy: 0.9799 - val_loss: 0.0196 - val_accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "60/61 [============================>.] - ETA: 0s - loss: 0.0507 - accuracy: 0.9852\n",
      "Epoch 00019: val_accuracy did not improve from 1.00000\n",
      "61/61 [==============================] - 10s 157ms/step - loss: 0.0503 - accuracy: 0.9854 - val_loss: 0.0091 - val_accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "60/61 [============================>.] - ETA: 0s - loss: 0.0519 - accuracy: 0.9833\n",
      "Epoch 00020: val_accuracy did not improve from 1.00000\n",
      "61/61 [==============================] - 9s 152ms/step - loss: 0.0512 - accuracy: 0.9836 - val_loss: 0.0050 - val_accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "60/61 [============================>.] - ETA: 0s - loss: 0.0615 - accuracy: 0.9799\n",
      "Epoch 00021: val_accuracy did not improve from 1.00000\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "61/61 [==============================] - 9s 148ms/step - loss: 0.0606 - accuracy: 0.9802 - val_loss: 0.0170 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "60/61 [============================>.] - ETA: 0s - loss: 0.0362 - accuracy: 0.9869\n",
      "Epoch 00022: val_accuracy did not improve from 1.00000\n",
      "61/61 [==============================] - 9s 149ms/step - loss: 0.0364 - accuracy: 0.9871 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "60/61 [============================>.] - ETA: 0s - loss: 0.0352 - accuracy: 0.9896\n",
      "Epoch 00023: val_accuracy did not improve from 1.00000\n",
      "61/61 [==============================] - 9s 151ms/step - loss: 0.0349 - accuracy: 0.9898 - val_loss: 0.0296 - val_accuracy: 0.9896\n",
      "Epoch 24/30\n",
      "60/61 [============================>.] - ETA: 0s - loss: 0.0468 - accuracy: 0.9847\n",
      "Epoch 00024: val_accuracy did not improve from 1.00000\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "61/61 [==============================] - 9s 148ms/step - loss: 0.0468 - accuracy: 0.9844 - val_loss: 0.0093 - val_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "60/61 [============================>.] - ETA: 0s - loss: 0.0324 - accuracy: 0.9874\n",
      "Epoch 00025: val_accuracy did not improve from 1.00000\n",
      "61/61 [==============================] - 9s 148ms/step - loss: 0.0326 - accuracy: 0.9871 - val_loss: 0.0050 - val_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "60/61 [============================>.] - ETA: 0s - loss: 0.0265 - accuracy: 0.9916\n",
      "Epoch 00026: val_accuracy did not improve from 1.00000\n",
      "61/61 [==============================] - 9s 149ms/step - loss: 0.0261 - accuracy: 0.9917 - val_loss: 0.0068 - val_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "60/61 [============================>.] - ETA: 0s - loss: 0.0360 - accuracy: 0.9859\n",
      "Epoch 00027: val_accuracy did not improve from 1.00000\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "61/61 [==============================] - 9s 149ms/step - loss: 0.0356 - accuracy: 0.9862 - val_loss: 0.0190 - val_accuracy: 0.9896\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/30\n",
      "60/61 [============================>.] - ETA: 0s - loss: 0.0385 - accuracy: 0.9873\n",
      "Epoch 00028: val_accuracy did not improve from 1.00000\n",
      "61/61 [==============================] - 9s 148ms/step - loss: 0.0380 - accuracy: 0.9875 - val_loss: 0.0053 - val_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "60/61 [============================>.] - ETA: 0s - loss: 0.0238 - accuracy: 0.9932\n",
      "Epoch 00029: val_accuracy did not improve from 1.00000\n",
      "61/61 [==============================] - 9s 149ms/step - loss: 0.0234 - accuracy: 0.9933 - val_loss: 0.0066 - val_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "60/61 [============================>.] - ETA: 0s - loss: 0.0386 - accuracy: 0.9880\n",
      "Epoch 00030: val_accuracy did not improve from 1.00000\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "61/61 [==============================] - 9s 150ms/step - loss: 0.0381 - accuracy: 0.9882 - val_loss: 0.0019 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "step_size_train = train_generator.n//train_generator.batch_size\n",
    "step_size_val = validation_generator.n//validation_generator.batch_size\n",
    "CNN.history = CNN.model.fit_generator(generator=train_generator,\n",
    "                   steps_per_epoch=step_size_train,\n",
    "                   epochs=30,\n",
    "                   validation_data=validation_generator,\n",
    "                   validation_steps=step_size_val,\n",
    "                   verbose=1,\n",
    "                   callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing out Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN.model.load_weights(BEST_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 118ms/step - loss: 0.0265 - accuracy: 0.9896\n"
     ]
    }
   ],
   "source": [
    "step_size_test = test_generator.n//test_generator.batch_size\n",
    "testing_model = CNN.model.evaluate_generator(\n",
    "    test_generator,\n",
    "    step_size_test,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = CNN.model.predict_generator(test_generator, test_generator.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8.52282450e-04 9.92833257e-01 6.31444622e-03]\n",
      " [3.38490150e-04 1.04784488e-06 9.99660492e-01]\n",
      " [2.46258657e-02 9.74705279e-01 6.68860681e-04]\n",
      " [2.97104862e-06 9.99468267e-01 5.28828532e-04]\n",
      " [3.43536056e-04 9.99272406e-01 3.84104060e-04]\n",
      " [9.98943269e-01 3.49398033e-04 7.07369763e-04]\n",
      " [8.06592579e-04 1.56973942e-06 9.99191821e-01]\n",
      " [9.99999881e-01 1.34374188e-14 6.56784920e-08]\n",
      " [2.27364013e-03 2.15967031e-08 9.97726381e-01]\n",
      " [1.36999530e-03 9.95647371e-01 2.98259384e-03]\n",
      " [4.88483999e-03 8.80944754e-07 9.95114207e-01]\n",
      " [6.29544229e-05 9.99858737e-01 7.83045689e-05]\n",
      " [1.14855054e-03 1.31704310e-05 9.98838246e-01]\n",
      " [1.75255560e-03 7.28056375e-06 9.98240113e-01]\n",
      " [3.13880046e-05 9.99814570e-01 1.54075169e-04]\n",
      " [1.55645991e-02 6.76397467e-04 9.83758926e-01]\n",
      " [4.30244021e-04 9.99487281e-01 8.24578965e-05]\n",
      " [3.12988907e-02 9.00442600e-01 6.82585016e-02]\n",
      " [9.32812877e-03 6.32764946e-04 9.90039051e-01]\n",
      " [9.92160499e-01 5.42197376e-03 2.41755298e-03]\n",
      " [5.78590715e-03 9.77761865e-01 1.64521988e-02]\n",
      " [6.53335452e-01 3.44767809e-01 1.89672166e-03]\n",
      " [9.98921514e-01 3.54518736e-04 7.23951729e-04]\n",
      " [9.99693871e-01 9.74354293e-07 3.05150141e-04]\n",
      " [9.99658704e-01 2.98726954e-05 3.11410986e-04]\n",
      " [8.84845911e-04 4.23235446e-03 9.94882822e-01]\n",
      " [9.99993205e-01 5.82986246e-08 6.83168537e-06]\n",
      " [9.98469293e-01 1.54917357e-10 1.53072248e-03]\n",
      " [1.57400282e-04 6.49380183e-07 9.99841928e-01]\n",
      " [1.39325610e-04 2.24523276e-07 9.99860406e-01]\n",
      " [2.42269471e-05 5.97412509e-07 9.99975204e-01]\n",
      " [9.99994755e-01 1.56175332e-07 5.15640704e-06]\n",
      " [2.27260156e-04 9.99698400e-01 7.44132194e-05]\n",
      " [2.58442294e-02 9.68419790e-01 5.73599525e-03]\n",
      " [6.28494238e-03 9.93694365e-01 2.07165976e-05]\n",
      " [9.99782264e-01 5.82894756e-07 2.17205219e-04]\n",
      " [1.02600209e-01 8.89815271e-01 7.58455321e-03]\n",
      " [9.98072147e-01 5.88291092e-04 1.33959448e-03]\n",
      " [9.45289561e-04 9.98894870e-01 1.59972347e-04]\n",
      " [7.43515696e-03 9.79614556e-01 1.29501941e-02]\n",
      " [9.99994516e-01 1.51430797e-07 5.36042262e-06]\n",
      " [1.51739514e-03 9.98441279e-01 4.13102389e-05]\n",
      " [9.99996543e-01 1.63514457e-07 3.35092795e-06]\n",
      " [9.99863744e-01 1.84301609e-06 1.34471833e-04]\n",
      " [3.30422510e-04 5.90201853e-06 9.99663711e-01]\n",
      " [1.47649518e-03 9.90421176e-01 8.10231268e-03]\n",
      " [2.90565845e-03 1.09663240e-07 9.97094274e-01]\n",
      " [1.19977130e-05 5.30381101e-07 9.99987483e-01]\n",
      " [9.70963180e-01 7.30954926e-05 2.89636850e-02]\n",
      " [5.75879880e-04 9.97772634e-01 1.65142131e-03]\n",
      " [6.41408114e-05 8.53852271e-06 9.99927282e-01]\n",
      " [9.99606550e-01 5.07949169e-11 3.93523456e-04]\n",
      " [9.99608934e-01 5.21950242e-05 3.38917627e-04]\n",
      " [1.57557952e-05 6.96137679e-12 9.99984264e-01]\n",
      " [3.63450759e-04 2.55497231e-04 9.99381065e-01]\n",
      " [9.99921083e-01 1.91716572e-05 5.96795981e-05]\n",
      " [6.60828082e-04 9.99247313e-01 9.17856596e-05]\n",
      " [2.32169428e-03 1.49505376e-03 9.96183217e-01]\n",
      " [6.35422347e-03 9.53283072e-01 4.03627604e-02]\n",
      " [9.32251941e-03 1.12073258e-06 9.90676403e-01]\n",
      " [1.20208249e-03 4.07452880e-08 9.98797894e-01]\n",
      " [6.26647903e-04 9.98470247e-01 9.03030217e-04]\n",
      " [4.82113985e-03 9.93483365e-01 1.69542176e-03]\n",
      " [1.62070082e-03 5.64733000e-07 9.98378754e-01]\n",
      " [1.10628561e-03 9.98708367e-01 1.85335652e-04]\n",
      " [4.62298468e-03 1.06917187e-05 9.95366335e-01]\n",
      " [9.93783057e-01 3.45634110e-03 2.76060821e-03]\n",
      " [8.54340851e-01 1.10077277e-01 3.55817862e-02]\n",
      " [2.44646333e-03 9.89774704e-01 7.77880894e-03]\n",
      " [7.30363885e-03 1.32876266e-05 9.92683113e-01]\n",
      " [9.95645821e-01 1.55819929e-03 2.79600685e-03]\n",
      " [3.66563573e-02 1.29444948e-06 9.63342369e-01]\n",
      " [9.98394310e-01 3.42472980e-04 1.26330904e-03]\n",
      " [1.45186309e-03 9.98346925e-01 2.01241812e-04]\n",
      " [5.66608433e-05 1.54003545e-04 9.99789298e-01]\n",
      " [1.31163368e-04 9.99549806e-01 3.19025421e-04]\n",
      " [9.99972701e-01 2.34496365e-05 3.75504123e-06]\n",
      " [2.01675488e-04 9.75284696e-01 2.45136432e-02]\n",
      " [4.13699570e-04 2.48299625e-06 9.99583781e-01]\n",
      " [9.99847293e-01 2.22122537e-12 1.52702080e-04]\n",
      " [9.96740401e-01 7.52278708e-12 3.25954938e-03]\n",
      " [5.48252836e-04 1.80524324e-07 9.99451578e-01]\n",
      " [4.30723140e-03 9.95574474e-01 1.18273274e-04]\n",
      " [8.78494058e-04 9.98825848e-01 2.95604637e-04]\n",
      " [9.99996066e-01 1.41437919e-08 3.96498899e-06]\n",
      " [1.30727352e-03 9.93292451e-01 5.40030049e-03]\n",
      " [1.20128578e-04 1.84450357e-06 9.99878049e-01]\n",
      " [5.06173633e-03 5.16785476e-05 9.94886577e-01]\n",
      " [9.99953270e-01 6.25507346e-06 4.05376486e-05]\n",
      " [9.99609411e-01 4.14344468e-05 3.49107286e-04]\n",
      " [3.67332309e-01 6.03820443e-01 2.88472790e-02]\n",
      " [4.13469225e-03 9.12765827e-05 9.95774090e-01]\n",
      " [9.99775231e-01 5.70843675e-08 2.24763688e-04]\n",
      " [9.99988914e-01 1.14307203e-10 1.11371573e-05]\n",
      " [3.72424419e-03 9.96165395e-01 1.10423498e-04]\n",
      " [8.85511562e-02 9.02045310e-01 9.40355659e-03]\n",
      " [9.97795463e-01 1.37279423e-08 2.20456626e-03]\n",
      " [3.10929082e-02 5.85697255e-11 9.68907118e-01]\n",
      " [3.76106764e-04 3.50352457e-06 9.99620318e-01]\n",
      " [1.00000000e+00 4.48811043e-20 1.97148093e-08]\n",
      " [4.29737411e-04 6.70225681e-11 9.99570310e-01]\n",
      " [3.16802971e-03 1.54805311e-04 9.96677160e-01]\n",
      " [1.27743697e-02 9.68509197e-01 1.87164824e-02]\n",
      " [3.16803867e-04 9.98415709e-01 1.26743235e-03]\n",
      " [3.88986827e-03 9.84406114e-01 1.17040221e-02]\n",
      " [1.85985482e-05 5.14676728e-08 9.99981403e-01]\n",
      " [2.50712037e-03 8.02304494e-05 9.97412622e-01]\n",
      " [2.68094445e-04 7.09421583e-05 9.99660969e-01]\n",
      " [9.99312758e-01 2.58152810e-04 4.29087842e-04]\n",
      " [1.48400199e-03 9.97821927e-01 6.94123388e-04]\n",
      " [4.62077405e-05 1.13795096e-09 9.99953747e-01]]\n"
     ]
    }
   ],
   "source": [
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "111"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_generator.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "111"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_generator.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "from PIL import Image\n",
    "\n",
    "img = Image.open(TEST_PATH+'scissors//WYOb0YuOVCMs7ebJ.png')#, target_size(60,60))\n",
    "img = img.resize((60,60)) \n",
    "img = image.img_to_array(img)\n",
    "img = img.reshape((1,)+img.shape)\n",
    "\n",
    "img_class = CNN.model.predict_classes(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2]\n"
     ]
    }
   ],
   "source": [
    "print(img_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
